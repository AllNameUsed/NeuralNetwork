{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fcdfd77-551a-4f3b-bddc-f6a4f70aa625",
   "metadata": {},
   "source": [
    "# Define global hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fc8dba-75ee-4bca-9d3a-f346feef7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MOMENTUM = 0.9\n",
    "LEARNING_RATE = 1e-3\n",
    "BETAS = (0.9, 0.999)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "seed = 6526026\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0137d-07b8-4f5d-9fa4-155ace3fb07c",
   "metadata": {},
   "source": [
    "# Define custom classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590d1525-bb1b-42d5-82cc-a5ffa933c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.resnet = torch.hub.load(\"pytorch/vision:v0.13.1\", \"resnet34\", weights='IMAGENET1K_V1')\n",
    "        self.fc = nn.Linear(1000, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # NOTE: Flatten has been done\n",
    "        features = self.resnet(x)\n",
    "        x = self.fc(features)\n",
    "        # output = F.log_softmax(x, dim=1)\n",
    "        return x, features\n",
    "    \n",
    "class KMNIST(Dataset):\n",
    "    def __init__(self, file_path, transforms):\n",
    "        CHOSEN_CLASSES = {\n",
    "        \"backpack\" : 0,\n",
    "        \"book\" : 1,\n",
    "        \"car\" : 2,\n",
    "        \"pizza\" : 3,\n",
    "        \"sandwich\" : 4,\n",
    "        \"snake\" : 5,\n",
    "        \"sock\" : 6,\n",
    "        \"tiger\" : 7,\n",
    "        \"tree\" : 8,\n",
    "        \"watermelon\" : 9,\n",
    "        }\n",
    "        labels = []\n",
    "        imgs = []\n",
    "        for path, subdirs, files in os.walk(file_path):\n",
    "            for name in files:\n",
    "                img_path = os.path.join(path, name)\n",
    "                c = img_path.split(\"\\\\\")\n",
    "                label = CHOSEN_CLASSES[c[1]]\n",
    "                imgs.append(img_path)\n",
    "                labels.append(label)\n",
    "        assert len(labels) == len(imgs)\n",
    "        self.labels = labels\n",
    "        self.imgs = imgs\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.imgs[index])\n",
    "        img = np.array(img)\n",
    "        label = self.labels[index]\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935007d2-b1ec-41c8-b2d6-ebb5e952ffb3",
   "metadata": {},
   "source": [
    "# Construct datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5698e87-06bd-4114-afc3-aec03e473ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.ConvertImageDtype(torch.float),\n",
    "    T.Normalize((0.485, 0.456, 0.406),  (0.229, 0.224, 0.225)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.Resize(size=(224,224),antialias = False)\n",
    "])\n",
    "\n",
    "test_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.ConvertImageDtype(torch.float),\n",
    "    T.Normalize((0.485, 0.456, 0.406),  (0.229, 0.224, 0.225)),\n",
    "    T.Resize(size=(224,224),antialias = False)\n",
    "])\n",
    "\n",
    "real_train = KMNIST(\n",
    "    \"data/real_train\",\n",
    "    train_transforms,\n",
    ")\n",
    "real_train_loader = DataLoader(\n",
    "    dataset = real_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)\n",
    "\n",
    "real_test = KMNIST(\n",
    "    \"data/real_test\",\n",
    "    test_transforms,\n",
    ")\n",
    "real_test_loader = DataLoader(\n",
    "    dataset = real_test,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)\n",
    "\n",
    "real_val = KMNIST(\n",
    "    \"data/real_train\",\n",
    "    test_transforms,\n",
    ")\n",
    "real_val_loader = DataLoader(\n",
    "    dataset = real_val,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)\n",
    "\n",
    "sketch_train = KMNIST(\n",
    "    \"data/sketch_train\",\n",
    "    train_transforms,\n",
    ")\n",
    "sketch_train_loader = DataLoader(\n",
    "    dataset = sketch_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)\n",
    "\n",
    "sketch_test = KMNIST(\n",
    "    \"data/sketch_test\",\n",
    "    test_transforms,\n",
    ")\n",
    "sketch_test_loader = DataLoader(\n",
    "    dataset = sketch_test,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)\n",
    "\n",
    "sketch_val = KMNIST(\n",
    "    \"data/sketch_train\",\n",
    "    test_transforms,\n",
    ")\n",
    "sketch_val_loader = DataLoader(\n",
    "    dataset = sketch_val,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd7db2-efc4-4cfb-80a6-3fd8ec7599d1",
   "metadata": {},
   "source": [
    "# Define training and testing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ac078c-17a9-43d8-b952-98adea91b705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Jerry Qian/.cache\\torch\\hub\\pytorch_vision_v0.13.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Training Model==================\n",
      "------------------Epoch number 1------------------\n",
      "\tModel training loss = 0.6963334679603577\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 86.80981595092024 , loss = 0.4734145700931549\n",
      "------------------Epoch number 2------------------\n",
      "\tModel training loss = 0.3486490249633789\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 94.68302658486708 , loss = 0.17777997255325317\n",
      "------------------Epoch number 3------------------\n",
      "\tModel training loss = 0.11765991151332855\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 97.54601226993866 , loss = 0.1550343632698059\n",
      "------------------Epoch number 4------------------\n",
      "\tModel training loss = 0.11546622216701508\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 98.72188139059304 , loss = 0.04537966102361679\n",
      "------------------Epoch number 5------------------\n",
      "\tModel training loss = 0.03811189532279968\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.5398773006135 , loss = 0.06035955250263214\n",
      "------------------Epoch number 6------------------\n",
      "\tModel training loss = 0.13476891815662384\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.79550102249489 , loss = 0.018253397196531296\n",
      "------------------Epoch number 7------------------\n",
      "\tModel training loss = 0.025981595739722252\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.69325153374233 , loss = 0.05004142224788666\n",
      "------------------Epoch number 8------------------\n",
      "\tModel training loss = 0.018868902698159218\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.79550102249489 , loss = 0.032628338783979416\n",
      "------------------Epoch number 9------------------\n",
      "\tModel training loss = 0.007126231212168932\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.84662576687117 , loss = 0.028557267040014267\n",
      "------------------Epoch number 10------------------\n",
      "\tModel training loss = 0.01671207882463932\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.94887525562372 , loss = 0.0380641371011734\n",
      "------------------Epoch number 11------------------\n",
      "\tModel training loss = 0.015399303287267685\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.89775051124744 , loss = 0.007580713368952274\n",
      "------------------Epoch number 12------------------\n",
      "\tModel training loss = 0.018080592155456543\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.84662576687117 , loss = 0.004550984129309654\n",
      "------------------Epoch number 13------------------\n",
      "\tModel training loss = 0.013685601763427258\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.89775051124744 , loss = 0.008065569214522839\n",
      "------------------Epoch number 14------------------\n",
      "\tModel training loss = 0.03768452629446983\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.84662576687117 , loss = 0.007495305500924587\n",
      "------------------Epoch number 15------------------\n",
      "\tModel training loss = 0.005091811530292034\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.94887525562372 , loss = 0.006271117366850376\n",
      "------------------Epoch number 16------------------\n",
      "\tModel training loss = 0.022208256646990776\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.89775051124744 , loss = 0.018310528248548508\n",
      "------------------Epoch number 17------------------\n",
      "\tModel training loss = 0.0027868454344570637\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 100.0 , loss = 0.007807999849319458\n",
      "------------------Epoch number 18------------------\n",
      "\tModel training loss = 0.008160640485584736\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.89775051124744 , loss = 0.0027314303442835808\n",
      "------------------Epoch number 19------------------\n",
      "\tModel training loss = 0.00889307539910078\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.94887525562372 , loss = 0.004404761828482151\n",
      "------------------Epoch number 20------------------\n",
      "\tModel training loss = 0.002439079573377967\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 99.89775051124744 , loss = 0.014915402978658676\n",
      "==================Finished Training==================\n",
      "\tBest model is epoch number 16\n",
      "\tBest model evaluation accuracy: 100.0\n",
      "\tBest model evaluation loss: tensor(0.0078, device='cuda:0')\n",
      "Model trained on sketch_train, testing on sketch_test, accuracy = 85.96908442330559 , testing loss = 0.7840451002120972\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to('cuda') \n",
    "            labels = labels.to('cuda') \n",
    "            # calculate outputs by running images through the network\n",
    "            outputs, _ = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    accuracy = 100 * correct / total \n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=20):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    max_acc = 0\n",
    "    best_epoch = 0\n",
    "    best_loss = 0\n",
    "    print(\"==================Training Model==================\")\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        print('------------------Epoch number '+ str(epoch + 1) +'------------------')\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            \n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            inputs = inputs.to('cuda') \n",
    "            labels = labels.to('cuda') \n",
    "            outputs, features = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"\\tModel training loss = \" + str(loss.item()))\n",
    "        print(\"\\tEvaluating model...\")\n",
    "        acc, l = test(model, val_loader)\n",
    "        print(\"\\tEvaluation accuracy \" + str(acc)+\" , loss = \" + str(l.item()))\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            best_epoch = epoch\n",
    "            best_loss = l\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "    print('==================Finished Training==================')\n",
    "    print('\\tBest model is epoch number ' + str(best_epoch))\n",
    "    print('\\tBest model evaluation accuracy: ' + str(max_acc))\n",
    "    print('\\tBest model evaluation loss: ' + str(best_loss))\n",
    "    return model\n",
    "\n",
    "model = Classifier().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "model = train_model(model, sketch_train_loader, sketch_val_loader, optimizer)\n",
    "accuracy, loss = test(model, sketch_test_loader)\n",
    "print(\"Model trained on sketch_train, testing on sketch_test, accuracy = \" + str(accuracy)+\" , testing loss = \" + str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb84c76-6086-42ac-a477-5191600bceaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Jerry Qian/.cache\\torch\\hub\\pytorch_vision_v0.13.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Training Model==================\n",
      "------------------Epoch number 1------------------\n",
      "\tModel training loss = 0.19999410212039948\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 56.28834355828221 , loss = 1.6830148696899414\n",
      "------------------Epoch number 2------------------\n",
      "\tModel training loss = 0.013411101885139942\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 58.640081799591 , loss = 1.7744139432907104\n",
      "------------------Epoch number 3------------------\n",
      "\tModel training loss = 0.00587375508621335\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 56.95296523517382 , loss = 1.8517279624938965\n",
      "------------------Epoch number 4------------------\n",
      "\tModel training loss = 0.020555445924401283\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.05521472392638 , loss = 2.1892364025115967\n",
      "------------------Epoch number 5------------------\n",
      "\tModel training loss = 0.0037861159071326256\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 56.441717791411044 , loss = 1.418652057647705\n",
      "------------------Epoch number 6------------------\n",
      "\tModel training loss = 0.05442135035991669\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 56.18609406952965 , loss = 1.6272540092468262\n",
      "------------------Epoch number 7------------------\n",
      "\tModel training loss = 0.0034329926129430532\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.719836400818 , loss = 2.352562665939331\n",
      "------------------Epoch number 8------------------\n",
      "\tModel training loss = 0.014369998127222061\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.31083844580777 , loss = 1.7724814414978027\n",
      "------------------Epoch number 9------------------\n",
      "\tModel training loss = 0.0037024379707872868\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.259713701431494 , loss = 2.141204833984375\n",
      "------------------Epoch number 10------------------\n",
      "\tModel training loss = 0.00021184429351706058\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.56646216768916 , loss = 2.5907163619995117\n",
      "------------------Epoch number 11------------------\n",
      "\tModel training loss = 0.007400492671877146\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.87321063394683 , loss = 1.3477460145950317\n",
      "------------------Epoch number 12------------------\n",
      "\tModel training loss = 0.0010656770318746567\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.82208588957055 , loss = 2.5306527614593506\n",
      "------------------Epoch number 13------------------\n",
      "\tModel training loss = 0.03462605178356171\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.464212678936605 , loss = 2.20878267288208\n",
      "------------------Epoch number 14------------------\n",
      "\tModel training loss = 0.01263592392206192\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.77096114519427 , loss = 3.5392470359802246\n",
      "------------------Epoch number 15------------------\n",
      "\tModel training loss = 0.00048737809993326664\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.97546012269939 , loss = 1.6765811443328857\n",
      "------------------Epoch number 16------------------\n",
      "\tModel training loss = 0.004876393359154463\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.61758691206544 , loss = 1.981269359588623\n",
      "------------------Epoch number 17------------------\n",
      "\tModel training loss = 0.0011658907169476151\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 56.90184049079755 , loss = 1.4776685237884521\n",
      "------------------Epoch number 18------------------\n",
      "\tModel training loss = 0.03680028021335602\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.77096114519427 , loss = 3.913459300994873\n",
      "------------------Epoch number 19------------------\n",
      "\tModel training loss = 0.0013329258654266596\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.10633946830266 , loss = 1.5547363758087158\n",
      "------------------Epoch number 20------------------\n",
      "\tModel training loss = 0.0007827123627066612\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 56.90184049079755 , loss = 3.0081989765167236\n",
      "==================Finished Training==================\n",
      "\tBest model is epoch number 1\n",
      "\tBest model evaluation accuracy: 58.640081799591\n",
      "\tBest model evaluation loss: tensor(1.7744, device='cuda:0')\n",
      "Model trained on real_train, testing on sketch_test, accuracy = 57.431629013079665 , testing loss = 1.8232697248458862\n"
     ]
    }
   ],
   "source": [
    "model = Classifier().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "model = train_model(model, real_train_loader, sketch_val_loader, optimizer)\n",
    "accuracy, loss = test(model, sketch_test_loader)\n",
    "print(\"Model trained on real_train, testing on sketch_test, accuracy = \" + str(accuracy)+\" , testing loss = \" + str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb60a0cf-9013-4304-aa89-b798f486d9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Jerry Qian/.cache\\torch\\hub\\pytorch_vision_v0.13.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Training Model==================\n",
      "------------------Epoch number 1------------------\n",
      "\tModel training loss = 0.11915460228919983\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 53.68098159509202 , loss = 2.1885628700256348\n",
      "------------------Epoch number 2------------------\n",
      "\tModel training loss = 0.30776286125183105\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 55.11247443762781 , loss = 1.412760615348816\n",
      "------------------Epoch number 3------------------\n",
      "\tModel training loss = 0.09659098833799362\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 56.441717791411044 , loss = 1.8395886421203613\n",
      "------------------Epoch number 4------------------\n",
      "\tModel training loss = 0.08528880029916763\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 55.77709611451943 , loss = 2.0007946491241455\n",
      "------------------Epoch number 5------------------\n",
      "\tModel training loss = 0.032275523990392685\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.0040899795501 , loss = 1.4959332942962646\n",
      "------------------Epoch number 6------------------\n",
      "\tModel training loss = 0.09187255054712296\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.31083844580777 , loss = 1.5273323059082031\n",
      "------------------Epoch number 7------------------\n",
      "\tModel training loss = 0.012239762581884861\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.719836400818 , loss = 1.1964031457901\n",
      "------------------Epoch number 8------------------\n",
      "\tModel training loss = 0.007866259664297104\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.259713701431494 , loss = 1.6833226680755615\n",
      "------------------Epoch number 9------------------\n",
      "\tModel training loss = 0.02433185465633869\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.87321063394683 , loss = 1.3532202243804932\n",
      "------------------Epoch number 10------------------\n",
      "\tModel training loss = 0.007632071152329445\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.515337423312886 , loss = 2.970149517059326\n",
      "------------------Epoch number 11------------------\n",
      "\tModel training loss = 0.01335603091865778\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.15746421267894 , loss = 1.5965406894683838\n",
      "------------------Epoch number 12------------------\n",
      "\tModel training loss = 0.0231582373380661\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 58.333333333333336 , loss = 1.759152889251709\n",
      "------------------Epoch number 13------------------\n",
      "\tModel training loss = 0.030125871300697327\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.719836400818 , loss = 2.0308334827423096\n",
      "------------------Epoch number 14------------------\n",
      "\tModel training loss = 0.008829672820866108\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 58.1799591002045 , loss = 1.4061498641967773\n",
      "------------------Epoch number 15------------------\n",
      "\tModel training loss = 0.008091595955193043\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.77096114519427 , loss = 2.620134115219116\n",
      "------------------Epoch number 16------------------\n",
      "\tModel training loss = 0.00654309568926692\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 58.1799591002045 , loss = 1.8893015384674072\n",
      "------------------Epoch number 17------------------\n",
      "\tModel training loss = 0.00928560271859169\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.719836400818 , loss = 1.8595739603042603\n",
      "------------------Epoch number 18------------------\n",
      "\tModel training loss = 0.0072174109518527985\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 56.646216768916155 , loss = 1.8232016563415527\n",
      "------------------Epoch number 19------------------\n",
      "\tModel training loss = 0.030551571398973465\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 57.0040899795501 , loss = 1.9418163299560547\n",
      "------------------Epoch number 20------------------\n",
      "\tModel training loss = 0.00830014981329441\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 56.74846625766871 , loss = 1.8841383457183838\n",
      "==================Finished Training==================\n",
      "\tBest model is epoch number 0\n",
      "\tBest model evaluation accuracy: 0\n",
      "\tBest model evaluation loss: 0\n",
      "Model trained on real_train, testing on sketch_test, accuracy = 57.431629013079665 , testing loss = 0.9275279641151428\n"
     ]
    }
   ],
   "source": [
    "def train_model_across_domain(model, source_train_loader, target_train_loader, val_loader, optimizer, num_epochs=20):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    max_acc = 0\n",
    "    best_epoch = 0\n",
    "    best_loss = 0\n",
    "    print(\"==================Training Model==================\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print('------------------Epoch number '+ str(epoch + 1) +'------------------')\n",
    "        itr = 0\n",
    "        for source_data, target_data in zip(real_train_loader, sketch_train_loader):\n",
    "            itr += 1\n",
    "            if itr >= 30:\n",
    "                break\n",
    "            source_inputs, source_labels = source_data\n",
    "            target_inputs, target_labels = target_data\n",
    "            source_inputs = source_inputs.to('cuda') \n",
    "            source_labels = source_labels.to('cuda') \n",
    "            target_inputs = target_inputs.to('cuda') \n",
    "            target_labels = target_labels.to('cuda') \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs, source_features = model(source_inputs)\n",
    "            loss = criterion(outputs, source_labels)\n",
    "            _, target_features = model(target_inputs)\n",
    "            MMD = (source_features/1000 - target_features/1000).pow(2).sum()\n",
    "            loss = 0.99 * loss + MMD * 0.01\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"\\tModel training loss = \" + str(loss.item()))\n",
    "        print(\"\\tEvaluating model...\")\n",
    "        acc, l = test(model, val_loader)\n",
    "        print(\"\\tEvaluation accuracy \" + str(acc)+\" , loss = \" + str(l.item()))\n",
    "        if loss < best_loss:\n",
    "            max_acc = acc\n",
    "            best_epoch = epoch\n",
    "            best_loss = l\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "    print('==================Finished Training==================')\n",
    "    print('\\tBest model is epoch number ' + str(best_epoch))\n",
    "    print('\\tBest model evaluation accuracy: ' + str(max_acc))\n",
    "    print('\\tBest model evaluation loss: ' + str(best_loss))\n",
    "    return model\n",
    "\n",
    "model = Classifier().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "model = train_model_across_domain(model = model, source_train_loader = real_train_loader, target_train_loader = sketch_train_loader, val_loader = sketch_val_loader, optimizer = optimizer)\n",
    "accuracy, loss = test(model, sketch_test_loader)\n",
    "print(\"Model trained on real_train, testing on sketch_test, accuracy = \" + str(accuracy)+\" , testing loss = \" + str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdba4b4-c730-4326-b352-f390c801508d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
