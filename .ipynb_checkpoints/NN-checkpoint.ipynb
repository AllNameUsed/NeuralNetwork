{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51cac496-1730-406d-9149-d764c7207e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: Real; Type: Train => Number of images: 3984\n",
      "Domain: Real; Type: Test => Number of images: 1712\n",
      "Domain: Sketch; Type: Train => Number of images: 1956\n",
      "Domain: Sketch; Type: Test => Number of images: 841\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "def file_count(path):\n",
    "    count = 0\n",
    "    for _, _, files in os.walk(path):\n",
    "        count += len(files)\n",
    "    return count\n",
    "\n",
    "print(\n",
    "    f\"Domain: Real; Type: Train => Number of images: {file_count('data/real_train')}\"\n",
    ")\n",
    "print(\n",
    "    f\"Domain: Real; Type: Test => Number of images: {file_count('data/real_test')}\"\n",
    ")\n",
    "print(\n",
    "    f\"Domain: Sketch; Type: Train => Number of images: {file_count('data/sketch_train')}\"\n",
    ")\n",
    "print(\n",
    "    f\"Domain: Sketch; Type: Test => Number of images: {file_count('data/sketch_test')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc0f43c0-07f4-47b4-a8be-f149c3c67089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.5625"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1956 / 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcdfd77-551a-4f3b-bddc-f6a4f70aa625",
   "metadata": {},
   "source": [
    "# Define global hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91fc8dba-75ee-4bca-9d3a-f346feef7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MOMENTUM = 0.9\n",
    "LEARNING_RATE = 1e-3\n",
    "BETAS = (0.9, 0.999)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "seed = 6526026\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0137d-07b8-4f5d-9fa4-155ace3fb07c",
   "metadata": {},
   "source": [
    "# Define custom classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590d1525-bb1b-42d5-82cc-a5ffa933c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.resnet = torch.hub.load(\"pytorch/vision:v0.13.1\", \"resnet34\", weights='IMAGENET1K_V1')\n",
    "        self.fc = nn.Linear(1000, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # NOTE: Flatten has been done\n",
    "        features = self.resnet(x)\n",
    "        x = self.fc(features)\n",
    "        # output = F.log_softmax(x, dim=1)\n",
    "        return x, features\n",
    "    \n",
    "class KMNIST(Dataset):\n",
    "    def __init__(self, file_path, transforms):\n",
    "        CHOSEN_CLASSES = {\n",
    "        \"backpack\" : 0,\n",
    "        \"book\" : 1,\n",
    "        \"car\" : 2,\n",
    "        \"pizza\" : 3,\n",
    "        \"sandwich\" : 4,\n",
    "        \"snake\" : 5,\n",
    "        \"sock\" : 6,\n",
    "        \"tiger\" : 7,\n",
    "        \"tree\" : 8,\n",
    "        \"watermelon\" : 9,\n",
    "        }\n",
    "        labels = []\n",
    "        imgs = []\n",
    "        for path, subdirs, files in os.walk(file_path):\n",
    "            for name in files:\n",
    "                img_path = os.path.join(path, name)\n",
    "                c = img_path.split(\"\\\\\")\n",
    "                label = CHOSEN_CLASSES[c[1]]\n",
    "                imgs.append(img_path)\n",
    "                labels.append(label)\n",
    "        assert len(labels) == len(imgs)\n",
    "        self.labels = labels\n",
    "        self.imgs = imgs\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.imgs[index])\n",
    "        img = np.array(img)\n",
    "        label = self.labels[index]\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935007d2-b1ec-41c8-b2d6-ebb5e952ffb3",
   "metadata": {},
   "source": [
    "# Construct datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5698e87-06bd-4114-afc3-aec03e473ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.ConvertImageDtype(torch.float),\n",
    "    T.Normalize((0.485, 0.456, 0.406),  (0.229, 0.224, 0.225)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.Resize(size=(224,224),antialias = False)\n",
    "])\n",
    "\n",
    "test_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.ConvertImageDtype(torch.float),\n",
    "    T.Normalize((0.485, 0.456, 0.406),  (0.229, 0.224, 0.225)),\n",
    "    T.Resize(size=(224,224),antialias = False)\n",
    "])\n",
    "\n",
    "real_train = KMNIST(\n",
    "    \"data/real_train\",\n",
    "    train_transforms,\n",
    ")\n",
    "real_train_loader = DataLoader(\n",
    "    dataset = real_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)\n",
    "\n",
    "real_test = KMNIST(\n",
    "    \"data/real_test\",\n",
    "    test_transforms,\n",
    ")\n",
    "real_test_loader = DataLoader(\n",
    "    dataset = real_test,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)\n",
    "\n",
    "real_val = KMNIST(\n",
    "    \"data/real_train\",\n",
    "    test_transforms,\n",
    ")\n",
    "real_val_loader = DataLoader(\n",
    "    dataset = real_val,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)\n",
    "\n",
    "sketch_train = KMNIST(\n",
    "    \"data/sketch_train\",\n",
    "    train_transforms,\n",
    ")\n",
    "sketch_train_loader = DataLoader(\n",
    "    dataset = sketch_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)\n",
    "\n",
    "sketch_test = KMNIST(\n",
    "    \"data/sketch_test\",\n",
    "    test_transforms,\n",
    ")\n",
    "sketch_test_loader = DataLoader(\n",
    "    dataset = sketch_test,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)\n",
    "\n",
    "sketch_val = KMNIST(\n",
    "    \"data/sketch_train\",\n",
    "    test_transforms,\n",
    ")\n",
    "sketch_val_loader = DataLoader(\n",
    "    dataset = sketch_val,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd7db2-efc4-4cfb-80a6-3fd8ec7599d1",
   "metadata": {},
   "source": [
    "# Define training and testing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ac078c-17a9-43d8-b952-98adea91b705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Jerry Qian/.cache\\torch\\hub\\pytorch_vision_v0.13.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Training Model==================\n",
      "------------------Epoch number 1------------------\n",
      "\tModel training loss = 0.6963334679603577\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 81.6884661117717 , loss = 0.2782331109046936\n",
      "------------------Epoch number 2------------------\n",
      "\tModel training loss = 0.3486490249633789\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 84.0665873959572 , loss = 0.25971749424934387\n",
      "------------------Epoch number 3------------------\n",
      "\tModel training loss = 0.11765991151332855\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 84.89892984542212 , loss = 0.6897740364074707\n",
      "------------------Epoch number 4------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m model \u001b[38;5;241m=\u001b[39m Classifier()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     63\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE, momentum\u001b[38;5;241m=\u001b[39mMOMENTUM)\n\u001b[1;32m---> 64\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msketch_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msketch_val_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 33\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):  \u001b[38;5;66;03m# loop over the dataset multiple times\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------------------Epoch number \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;66;03m# get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[2], line 50\u001b[0m, in \u001b[0;36mKMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     48\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[index]\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 50\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img, label\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torchvision\\transforms\\functional.py:155\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# backward compatibility\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test(model, test_loader):\n",
    "    # TODO: Implement testing code, you should `RETURN` the testing accuracy and loss on the given test_loader\n",
    "    #       You should define the loss function (cross-entropy loss) within this function\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to('cuda') \n",
    "            labels = labels.to('cuda') \n",
    "            # calculate outputs by running images through the network\n",
    "            outputs, _ = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    accuracy = 100 * correct / total \n",
    "    return accuracy, loss\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=20):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    max_acc = 0\n",
    "    best_epoch = 0\n",
    "    best_loss = 0\n",
    "    print(\"==================Training Model==================\")\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        print('------------------Epoch number '+ str(epoch + 1) +'------------------')\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            \n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            inputs = inputs.to('cuda') \n",
    "            labels = labels.to('cuda') \n",
    "            outputs, features = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"\\tModel training loss = \" + str(loss.item()))\n",
    "        print(\"\\tEvaluating model...\")\n",
    "        acc, l = test(model, sketch_test_loader)\n",
    "        print(\"\\tEvaluation accuracy \" + str(acc)+\" , loss = \" + str(l.item()))\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            best_epoch = epoch\n",
    "            best_loss = l\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "    print('==================Finished Training==================')\n",
    "    print('\\tBest model is epoch number ' + str(best_epoch))\n",
    "    print('\\tBest model evaluation accuracy: ' + str(max_acc))\n",
    "    print('\\tBest model evaluation loss: ' + str(best_loss))\n",
    "    return model\n",
    "\n",
    "model = Classifier().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "model = train_model(model, sketch_train_loader, sketch_val_loader, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb84c76-6086-42ac-a477-5191600bceaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Jerry Qian/.cache\\torch\\hub\\pytorch_vision_v0.13.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Training Model==================\n",
      "------------------Epoch number 1------------------\n",
      "\tModel training loss = 1.322391152381897\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 55.8858501783591 , loss = 2.493804454803467\n",
      "------------------Epoch number 2------------------\n",
      "\tModel training loss = 0.038123782724142075\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 59.096313912009514 , loss = 1.5565779209136963\n",
      "------------------Epoch number 3------------------\n",
      "\tModel training loss = 0.020405467599630356\n",
      "\tEvaluating model...\n",
      "\tEvaluation accuracy 59.571938168846614 , loss = 0.4256483018398285\n",
      "------------------Epoch number 4------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Classifier()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE, momentum\u001b[38;5;241m=\u001b[39mMOMENTUM)\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_val_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m accuracy, loss \u001b[38;5;241m=\u001b[39m test(model, sketch_test_loader)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel trained on real_train, testing on sketch_test, accuracy = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(accuracy)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m , testing loss = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(loss\u001b[38;5;241m.\u001b[39mitem()))\n",
      "Cell \u001b[1;32mIn[5], line 33\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):  \u001b[38;5;66;03m# loop over the dataset multiple times\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------------------Epoch number \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;66;03m# get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[2], line 47\u001b[0m, in \u001b[0;36mKMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m     46\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs[index])\n\u001b[1;32m---> 47\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[index]\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\PIL\\Image.py:701\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    699\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 701\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\PIL\\Image.py:758\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[1;34m(self, encoder_name, *args)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;241m==\u001b[39m ():\n\u001b[0;32m    756\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m--> 758\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# accuracy, loss = test(model, sketch_test_loader)\n",
    "# print(\"Model trained on sketch_train, testing on sketch_test, accuracy = \" + str(accuracy)+\" , testing loss = \" + str(loss.item()))\n",
    "\n",
    "model = Classifier().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "model = train_model(model, real_train_loader, real_val_loader, optimizer)\n",
    "accuracy, loss = test(model, sketch_test_loader)\n",
    "print(\"Model trained on real_train, testing on sketch_test, accuracy = \" + str(accuracy)+\" , testing loss = \" + str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb60a0cf-9013-4304-aa89-b798f486d9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Jerry Qian/.cache\\torch\\hub\\pytorch_vision_v0.13.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================Training Model==================\n",
      "------------------Epoch number 1------------------\n",
      "\tModel training loss = tensor(0.6791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\tEvaluating model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m model \u001b[38;5;241m=\u001b[39m Classifier()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     47\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE, momentum\u001b[38;5;241m=\u001b[39mMOMENTUM)\n\u001b[1;32m---> 48\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_across_domain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_train_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreal_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_train_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msketch_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msketch_val_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m accuracy, loss \u001b[38;5;241m=\u001b[39m test(model, sketch_test_loader)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel trained on real_train, testing on sketch_test, accuracy = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(accuracy)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m , testing loss = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(loss\u001b[38;5;241m.\u001b[39mitem()))\n",
      "Cell \u001b[1;32mIn[15], line 34\u001b[0m, in \u001b[0;36mtrain_model_across_domain\u001b[1;34m(model, source_train_loader, target_train_loader, val_loader, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mEvaluating model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m acc, l \u001b[38;5;241m=\u001b[39m test(model, sketch_test_loader)\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mEvaluation accuracy \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mds\u001b[49m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m , loss = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l))\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m acc \u001b[38;5;241m>\u001b[39m max_acc:\n\u001b[0;32m     36\u001b[0m     max_acc \u001b[38;5;241m=\u001b[39m acc\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "def train_model_across_domain(model, source_train_loader, target_train_loader, val_loader, optimizer, num_epochs=20):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    max_acc = 0\n",
    "    best_epoch = 0\n",
    "    best_loss = 0\n",
    "    print(\"==================Training Model==================\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print('------------------Epoch number '+ str(epoch + 1) +'------------------')\n",
    "        itr = 0\n",
    "        for source_data, target_data in zip(real_train_loader, sketch_train_loader):\n",
    "            itr += 1\n",
    "            if itr >= 30:\n",
    "                break\n",
    "            source_inputs, source_labels = source_data\n",
    "            target_inputs, target_labels = target_data\n",
    "            source_inputs = source_inputs.to('cuda') \n",
    "            source_labels = source_labels.to('cuda') \n",
    "            target_inputs = target_inputs.to('cuda') \n",
    "            target_labels = target_labels.to('cuda') \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs, source_features = model(source_inputs)\n",
    "            loss = criterion(outputs, source_labels)\n",
    "            _, target_features = model(target_inputs)\n",
    "            MMD = (source_features/1000 - target_features/1000).pow(2).sum()\n",
    "            loss += MMD\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"\\tModel training loss = \" + str(loss))\n",
    "        print(\"\\tEvaluating model...\")\n",
    "        acc, l = test(model, sketch_test_loader)\n",
    "        print(\"\\tEvaluation accuracy \" + str(acc)+\" , loss = \" + str(l))\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            best_epoch = epoch\n",
    "            best_loss = l\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "    print('==================Finished Training==================')\n",
    "    print('\\tBest model is epoch number ' + str(best_epoch))\n",
    "    print('\\tBest model evaluation accuracy: ' + str(max_acc))\n",
    "    print('\\tBest model evaluation loss: ' + str(best_loss))\n",
    "    return model\n",
    "\n",
    "model = Classifier().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "model = train_model_across_domain(model = model, source_train_loader = real_train_loader, target_train_loader = sketch_train_loader, val_loader = sketch_val_loader, optimizer = optimizer)\n",
    "accuracy, loss = test(model, sketch_test_loader)\n",
    "print(\"Model trained on real_train, testing on sketch_test, accuracy = \" + str(accuracy)+\" , testing loss = \" + str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8a3b8-dead-4583-84e8-164b488e5e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
